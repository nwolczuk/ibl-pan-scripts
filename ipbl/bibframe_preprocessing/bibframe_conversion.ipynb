{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "\n",
    "from rdflib import Graph, Namespace, URIRef, Literal, BNode\n",
    "from rdflib.namespace import RDF, RDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init operations\n",
    "ELB = Namespace(\"http://literarybibliography.eu/\")\n",
    "BF = Namespace(\"http://id.loc.gov/ontologies/bibframe/\")\n",
    "g = Graph()\n",
    "g.bind(\"elb\", ELB)\n",
    "g.bind(\"bf\", BF)\n",
    "\n",
    "uri_base = 'http://literarybibliography.eu/'\n",
    "output_df = pd.DataFrame(columns=['subject', 'type', 'predicate', 'object'])\n",
    "\n",
    "entities_dict = {\n",
    "        'authors': {},\n",
    "        'subjects': {},\n",
    "        'genreforms': {},\n",
    "    }\n",
    "\n",
    "flow_control = {\n",
    "        'work_last_id': 0,\n",
    "        'instance_last_id': 0,\n",
    "        'item_last_id': 0,\n",
    "        'topic_last_id': 0,\n",
    "        'genreform_last_id': 0,\n",
    "        'author_last_id': 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_df(df_name):\n",
    "    df = pd.read_csv(df_name).fillna('')\n",
    "    df = df[df['do PBL'] == True]\n",
    "    return df\n",
    "\n",
    "def clear_viaf_uri(url):\n",
    "    if uri := re.match(r'https://viaf\\.org/viaf/\\d+', url):\n",
    "        return uri.group(0) + '/'\n",
    "    \n",
    "def get_viaf_label(url):\n",
    "    if viaf_uri := clear_viaf_uri(url):\n",
    "        url = viaf_uri + 'viaf.json'\n",
    "        response = requests.get(url)\n",
    "        if response.ok:\n",
    "            if 'redirect' not in response.json():\n",
    "                try:\n",
    "                    label = response.json()['mainHeadings']['data'][0]['text']\n",
    "                except KeyError:\n",
    "                    label = response.json()['mainHeadings']['data']['text']\n",
    "                return label\n",
    "    \n",
    "def get_filmpolski_label(url):\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        label = soup.find('article', {'id': 'film'}).find('h1').text\n",
    "        return label\n",
    "\n",
    "def preprocess_authors(df, with_viaf=False):\n",
    "    authors_list = set(zip(df['Autor'], df['VIAF autor 1'], df['VIAF autor 2'], df['VIAF autor 3']))\n",
    "    for author_tuple in authors_list:\n",
    "        author_splitted = author_tuple[0].split('|')\n",
    "        for idx, aut in enumerate(author_splitted):\n",
    "            if idx > 2: break\n",
    "            label = aut.strip()\n",
    "            if (viaf_url := author_tuple[idx + 1]):\n",
    "                if with_viaf:\n",
    "                    viaf_label = get_viaf_label(viaf_url)\n",
    "                else: viaf_label = None\n",
    "                viaf_uri = clear_viaf_uri(viaf_url)\n",
    "            else:\n",
    "                viaf_label = None\n",
    "                viaf_uri = None   \n",
    "            if label not in entities_dict['authors']:\n",
    "                last_id = flow_control['author_last_id']\n",
    "                author_id = str(last_id + 1).zfill(8)\n",
    "                entities_dict['authors'][label] = {\n",
    "                        'author_id': author_id,\n",
    "                        'viaf_uri': viaf_uri,\n",
    "                        'viaf_label': viaf_label,\n",
    "                        'bibframe_type': 'bf:Agent',\n",
    "                    }\n",
    "                flow_control['author_last_id'] += 1\n",
    "            \n",
    "def preprocess_topics(df):\n",
    "    topics_map = {\n",
    "            'czasopismo': 'Work',\n",
    "            'film': 'MovingImage',\n",
    "            'instytucja': 'Organization',\n",
    "            'kraj': 'Place',\n",
    "            'książka': 'Work',\n",
    "            'miejscowość': 'Place',\n",
    "            'osoba': 'Person',\n",
    "            'spektakl': 'Work',\n",
    "            'wydarzenie': 'Event',\n",
    "        }\n",
    "    \n",
    "    # entities\n",
    "    df_entities = df[['byt 1', 'zewnętrzny identyfikator bytu 1', 'byt 2', 'zewnętrzny identyfikator bytu 2', 'byt 3', 'zewnętrzny identyfikator bytu 3']]\n",
    "    entities_list = list(zip(df_entities['byt 1'], df_entities['zewnętrzny identyfikator bytu 1'])) + list(zip(df_entities['byt 2'], df_entities['zewnętrzny identyfikator bytu 2'])) + list(zip(df_entities['byt 3'], df_entities['zewnętrzny identyfikator bytu 3']))\n",
    "    entities_list = [e for e in entities_list if e[0] and e[1]]\n",
    "        \n",
    "    for elem in tqdm(entities_list):\n",
    "        if elem[1].startswith('https://viaf.org/'):\n",
    "            pass\n",
    "            # label = get_viaf_label(elem[1])\n",
    "            # if label:\n",
    "            #    uri = clear_viaf_uri(url)\n",
    "            #    key = uri\n",
    "            #    bibframe_type = 'bf:' + topics_map[elem[0]]\n",
    "        elif elem[1].startswith('https://filmpolski.pl/'):\n",
    "            label = get_filmpolski_label(elem[1])\n",
    "            if label:\n",
    "                uri = elem[1]\n",
    "                key = uri\n",
    "                bibframe_type = 'bf:' + topics_map[elem[0]]\n",
    "        if key and key not in entities_dict['subjects']:\n",
    "            last_id = flow_control['topic_last_id']\n",
    "            topic_uri = uri_base + 'subjects/subject' + str(last_id + 1).zfill(8)\n",
    "            entities_dict['subjects'][key] = {\n",
    "                    'label': label,\n",
    "                    'uri': topic_uri,\n",
    "                    'external_uri': uri,\n",
    "                    'bibframe_type': bibframe_type,\n",
    "                }\n",
    "            flow_control['topic_last_id'] += 1\n",
    "    \n",
    "    # other subjects\n",
    "    topics = set(df['Sekcja'])\n",
    "    for topic in topics:\n",
    "        if topic not in entities_dict['subjects']:\n",
    "            last_id = flow_control['topic_last_id']\n",
    "            topic_id = str(last_id + 1).zfill(8)\n",
    "            entities_dict['subjects'][topic] = {\n",
    "                    'topic_id': topic_id,\n",
    "                    'external_uri': None,\n",
    "                    'bibframe_type': 'bf:Topic',\n",
    "                }\n",
    "            flow_control['topic_last_id'] += 1\n",
    "        \n",
    "def preprocess_forms(df):\n",
    "    forms = [\n",
    "                'artykuł', \n",
    "                'esej',\n",
    "                'felieton',\n",
    "                'inne',\n",
    "                'kalendarium',\n",
    "                'kult',\n",
    "                'list',\n",
    "                'miniatura prozą',\n",
    "                'nota',\n",
    "                'opowiadanie',\n",
    "                'poemat',\n",
    "                'proza',\n",
    "                'proza poetycka',\n",
    "                'recenzja',\n",
    "                'reportaż',\n",
    "                'rozmyślanie religijne',\n",
    "                'scenariusz',\n",
    "                'słownik',\n",
    "                'sprostowanie',\n",
    "                'szkic',\n",
    "                'teksty dramatyczne',\n",
    "                'wiersz',\n",
    "                'wpis blogowy',\n",
    "                'wspomnienie',\n",
    "                'wypowiedź',\n",
    "                'wywiad',\n",
    "                'zgon',\n",
    "            ]\n",
    "    \n",
    "    for idx, form in enumerate(forms):\n",
    "        form_uri = uri_base + 'genreForms/genreform' + str(idx + 1).zfill(8)\n",
    "        entities_dict['genreforms'][form] = form_uri\n",
    "    \n",
    "def preprocess_row(idx, row):\n",
    "\n",
    "    work_id = str(flow_control.get('work_last_id') + 1).zfill(8)\n",
    "    work = ELB[f'works/{work_id}']\n",
    "    flow_control['work_last_id'] += 1\n",
    "    g.add((work, RDF.type, BF.Work))\n",
    "    \n",
    "    instance_id = str(flow_control.get('instance_last_id') + 1).zfill(8)\n",
    "    instance = ELB[f'instances/{instance_id}']\n",
    "    flow_control['instance_last_id'] += 1\n",
    "    g.add((work, BF.hasInstance, instance))\n",
    "    g.add((instance, RDF.type, BF.Instance))\n",
    "    g.add((instance, BF.instanceOf, work))\n",
    "    \n",
    "    item_id = str(flow_control.get('item_last_id') + 1).zfill(8)\n",
    "    item = ELB[f'items/{item_id}']\n",
    "    flow_control['item_last_id'] += 1\n",
    "    g.add((instance, BF.hasItem, item))\n",
    "    g.add((item, RDF.type, BF.Item))\n",
    "    g.add((item, BF.itemOf, instance))\n",
    "\n",
    "    for col, value in row.items():\n",
    "        # value = value.item()\n",
    "        match col:\n",
    "            case 'Link':\n",
    "                g.add((item, BF.electronicLocator, URIRef(value.strip())))\n",
    "                \n",
    "            case 'Data publikacji':\n",
    "                g.add((instance, BF.originDate, Literal(value.strip())))\n",
    "                \n",
    "            case 'Autor':\n",
    "                for author in value.split('|'):\n",
    "                    author_dct = entities_dict['authors'].get(author.strip())\n",
    "                    if author_dct:\n",
    "                        author_id, viaf_uri, viaf_label = author_dct['author_id'], author_dct['viaf_uri'], author_dct['viaf_label'] # it is possible to use locals().update(author_dct)\n",
    "                        label = viaf_label if viaf_label else author\n",
    "                        \n",
    "                        # create an Agent\n",
    "                        agent = ELB[f'agents/{author_id}']\n",
    "                        g.add((agent, RDF.type, BF.Agent))\n",
    "                        g.add((agent, RDF.type, BF.Person))\n",
    "                        g.add((agent, RDFS.label, Literal(label)))\n",
    "                        if viaf_uri:\n",
    "                            identifier = BNode()\n",
    "                            g.add((identifier, RDF.type, BF.Identifier))\n",
    "                            g.add((identifier, RDF.value, Literal(viaf_uri)))\n",
    "                            g.add((agent, BF.identifiedBy, identifier))\n",
    "        \n",
    "                        # add Agent\n",
    "                        contribution = BNode()\n",
    "                        g.add((work, BF.contribution, contribution))\n",
    "                        g.add((contribution, RDF.type, BF.Contribution))\n",
    "                        g.add((contribution, RDF.type, BF.PrimaryContribution))\n",
    "                        g.add((contribution, BF.agent, agent))\n",
    "\n",
    "                        # add role\n",
    "                        author_role = URIRef('http://id.loc.gov/vocabulary/relators/aut')\n",
    "                        g.add((contribution, BF.role, author_role))\n",
    "                        g.add((author_role, RDF.type, BF.Role))\n",
    "                        g.add((author_role, RDFS.label, Literal('author')))\n",
    "                \n",
    "            case 'do PBL':\n",
    "                pass\n",
    "            \n",
    "            case 'VIAF autor 1':\n",
    "                pass\n",
    "            \n",
    "            case 'VIAF autor 2':\n",
    "                pass\n",
    "            \n",
    "            case 'VIAF autor 3':\n",
    "                pass\n",
    "            \n",
    "            case 'Sekcja':\n",
    "                topic_dct = entities_dict['subjects'].get(value.strip())\n",
    "                if topic_dct:\n",
    "                    topic_id = topic_dct['topic_id']\n",
    "                    topic = ELB[f'subjects/{topic_id}']\n",
    "                    g.add((work, BF.subject, topic))\n",
    "                    g.add((topic, RDF.type, BF.Topic))\n",
    "                    g.add((topic, RDFS.label, Literal(value.strip())))\n",
    "                \n",
    "            case 'Tytuł artykułu':                \n",
    "                title = BNode()\n",
    "                g.add((work, BF.title, title))\n",
    "                g.add((title, RDF.type, BF.Title))\n",
    "                g.add((title, BF.mainTitle, Literal(value.strip())))\n",
    "                \n",
    "            case 'Opis':\n",
    "                summary = BNode()\n",
    "                g.add((work, BF.summary, summary))\n",
    "                g.add((summary, RDF.type, BF.Summary))\n",
    "                g.add((summary, RDFS.label, Literal(value.strip())))\n",
    "                \n",
    "            case 'Numer':\n",
    "                enumeration = BNode()\n",
    "                g.add((item, BF.enumerationAndChronology, enumeration))\n",
    "                g.add((enumeration, RDF.type, BF.Enumeration))\n",
    "                if isinstance(value, float): value = int(value)\n",
    "                g.add((enumeration, RDFS.label, Literal(str(value).strip())))\n",
    "            \n",
    "            case 'Tagi':\n",
    "                for tag in value.split('|'):\n",
    "                    topic_dct = entities_dict['subjects'].get(tag.strip())\n",
    "                    if topic_dct:\n",
    "                        topic_id = topic_dct['topic_id']\n",
    "                        topic = ELB[f'subjects/{topic_id}']\n",
    "                        g.add((work, BF.subject, topic))\n",
    "                        g.add((topic, RDF.type, BF.Topic))\n",
    "                        g.add((topic, RDFS.label, Literal(value.strip())))\n",
    "\n",
    "            case 'forma/gatunek':\n",
    "                genreform = BNode()\n",
    "                g.add((work, BF.genreForm, genreform))\n",
    "                g.add((genreform, RDF.type, BF.GenreForm))\n",
    "                g.add((genreform, RDFS.label, Literal(value.strip())))\n",
    "                \n",
    "            case 'hasła przedmiotowe':\n",
    "                # matching with lcsh\n",
    "                pass\n",
    "            \n",
    "            case 'zewnętrzny identyfikator bytu 1' | 'zewnętrzny identyfikator bytu 2' | 'zewnętrzny identyfikator bytu 3':\n",
    "                topic_dct = entities_dict['subjects'].get(value.strip())\n",
    "                if topic_dct:\n",
    "                    match topic_dct['bibframe_type']:\n",
    "                        case 'bf:Work':\n",
    "                            pass\n",
    "                        case 'bf:MovingImage':\n",
    "                            uri = topic_dct['external_uri']\n",
    "                            movie_work = URIRef(uri)\n",
    "                            g.add((work, BF.subject, movie_work))\n",
    "                            g.add((movie_work, RDF.type, BF.Work))\n",
    "                            g.add((movie_work, RDF.type, BF.MovingImage))\n",
    "                            title = BNode()\n",
    "                            g.add((movie_work, BF.title, title))\n",
    "                            g.add((title, RDF.type, BF.Title))\n",
    "                            g.add((title, BF.mainTitle, Literal(topic_dct['label'])))\n",
    "                        case 'bf:Organization':\n",
    "                            pass\n",
    "                        case 'bf:Place':\n",
    "                            pass\n",
    "                        case 'bf:Person':\n",
    "                            pass\n",
    "                        case 'bf:Event':\n",
    "                            pass\n",
    "            \n",
    "            case 'byt 1':\n",
    "                pass\n",
    "\n",
    "            case 'byt 2':\n",
    "                pass\n",
    "            \n",
    "            case 'byt 3':\n",
    "                pass\n",
    "            \n",
    "            case 'adnotacje':\n",
    "                pass\n",
    "            \n",
    "            case 'Linki zewnętrzne':\n",
    "                pass\n",
    "            \n",
    "            case 'Linki do zdjęć':\n",
    "                pass\n",
    "\n",
    "            case _:\n",
    "                pass\n",
    "\n",
    "\n",
    "def preprocess_df(df):\n",
    "    pass\n",
    "\n",
    "def save_graph():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "input_df_names = ['dwutygodnik_2024-05-06 - Posts.csv']\n",
    "df = load_input_df(input_df_names[0])\n",
    "sample = df.iloc[8:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  8.65it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_authors(sample)\n",
    "preprocess_topics(sample)\n",
    "preprocess_forms(sample)\n",
    "for index, row in sample.iterrows():\n",
    "    preprocess_row(index, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<rdf:RDF\n",
      "  xmlns:bf=\"http://id.loc.gov/ontologies/bibframe/\"\n",
      "  xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
      "  xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"\n",
      ">\n",
      "  <bf:Item rdf:about=\"http://literarybibliography.eu/items/00000002\">\n",
      "    <bf:itemOf>\n",
      "      <bf:Instance rdf:about=\"http://literarybibliography.eu/instances/00000002\">\n",
      "        <bf:instanceOf rdf:resource=\"http://literarybibliography.eu/works/00000002\"/>\n",
      "        <bf:hasItem rdf:resource=\"http://literarybibliography.eu/items/00000002\"/>\n",
      "        <bf:originDate>2024-04-01</bf:originDate>\n",
      "      </bf:Instance>\n",
      "    </bf:itemOf>\n",
      "    <bf:electronicLocator rdf:resource=\"https://www.dwutygodnik.com/artykul/11208-moliwoci.html\"/>\n",
      "    <bf:enumerationAndChronology>\n",
      "      <bf:Enumeration rdf:nodeID=\"N5bd093491b8547afb2694319aa5c0d33\">\n",
      "        <rdfs:label>383</rdfs:label>\n",
      "      </bf:Enumeration>\n",
      "    </bf:enumerationAndChronology>\n",
      "  </bf:Item>\n",
      "  <bf:Work rdf:about=\"http://literarybibliography.eu/works/00000002\">\n",
      "    <bf:hasInstance rdf:resource=\"http://literarybibliography.eu/instances/00000002\"/>\n",
      "    <bf:contribution>\n",
      "      <bf:Contribution rdf:nodeID=\"N6a92806362b047c1b38e8bf9df09b8cb\">\n",
      "        <rdf:type rdf:resource=\"http://id.loc.gov/ontologies/bibframe/PrimaryContribution\"/>\n",
      "        <bf:agent rdf:resource=\"http://literarybibliography.eu/agents/00000001\"/>\n",
      "        <bf:role rdf:resource=\"http://id.loc.gov/vocabulary/relators/aut\"/>\n",
      "      </bf:Contribution>\n",
      "    </bf:contribution>\n",
      "    <bf:subject>\n",
      "      <bf:Topic rdf:about=\"http://literarybibliography.eu/subjects/00000003\">\n",
      "        <rdfs:label>Film</rdfs:label>\n",
      "      </bf:Topic>\n",
      "    </bf:subject>\n",
      "    <bf:subject>\n",
      "      <bf:Work rdf:about=\"https://filmpolski.pl/fp/index.php?film=1264623\">\n",
      "        <rdf:type rdf:resource=\"http://id.loc.gov/ontologies/bibframe/MovingImage\"/>\n",
      "        <bf:title>\n",
      "          <bf:Title rdf:nodeID=\"N9e066452dd614dc1a892bc13369d8684\">\n",
      "            <bf:mainTitle>CZERWONE MAKI</bf:mainTitle>\n",
      "          </bf:Title>\n",
      "        </bf:title>\n",
      "      </bf:Work>\n",
      "    </bf:subject>\n",
      "    <bf:title>\n",
      "      <bf:Title rdf:nodeID=\"N24aaeecd75434f5a8b47f1dbfedc28b3\">\n",
      "        <bf:mainTitle>Możliwości</bf:mainTitle>\n",
      "      </bf:Title>\n",
      "    </bf:title>\n",
      "    <bf:summary>\n",
      "      <bf:Summary rdf:nodeID=\"N72e3c82dbb304773b3b9e459cbcc7320\">\n",
      "        <rdfs:label>„Czerwone maki” to ostatni akord zaplanowanej na lata akcji stworzenia nowego kina historycznego nad Wisłą. Można śmiało powiedziec, że akcja się nie udała</rdfs:label>\n",
      "      </bf:Summary>\n",
      "    </bf:summary>\n",
      "    <bf:genreForm>\n",
      "      <bf:GenreForm rdf:nodeID=\"Nf364627bb3614a08a854fca594c539e2\">\n",
      "        <rdfs:label>recenzja</rdfs:label>\n",
      "      </bf:GenreForm>\n",
      "    </bf:genreForm>\n",
      "  </bf:Work>\n",
      "  <bf:Agent rdf:about=\"http://literarybibliography.eu/agents/00000002\">\n",
      "    <rdf:type rdf:resource=\"http://id.loc.gov/ontologies/bibframe/Person\"/>\n",
      "    <rdfs:label>Joanna Mąkowska</rdfs:label>\n",
      "    <bf:identifiedBy>\n",
      "      <bf:Identifier rdf:nodeID=\"Neb01e19a09c544ec8490f6d3fc8607f4\">\n",
      "        <rdf:value>https://viaf.org/viaf/75160307389057741639/</rdf:value>\n",
      "      </bf:Identifier>\n",
      "    </bf:identifiedBy>\n",
      "  </bf:Agent>\n",
      "  <bf:Work rdf:about=\"http://literarybibliography.eu/works/00000001\">\n",
      "    <bf:hasInstance>\n",
      "      <bf:Instance rdf:about=\"http://literarybibliography.eu/instances/00000001\">\n",
      "        <bf:instanceOf rdf:resource=\"http://literarybibliography.eu/works/00000001\"/>\n",
      "        <bf:hasItem rdf:resource=\"http://literarybibliography.eu/items/00000001\"/>\n",
      "        <bf:originDate>2024-04-01</bf:originDate>\n",
      "      </bf:Instance>\n",
      "    </bf:hasInstance>\n",
      "    <bf:contribution>\n",
      "      <bf:Contribution rdf:nodeID=\"N03f5d28c94544598b4e29cce4e15921a\">\n",
      "        <rdf:type rdf:resource=\"http://id.loc.gov/ontologies/bibframe/PrimaryContribution\"/>\n",
      "        <bf:agent rdf:resource=\"http://literarybibliography.eu/agents/00000002\"/>\n",
      "        <bf:role rdf:resource=\"http://id.loc.gov/vocabulary/relators/aut\"/>\n",
      "      </bf:Contribution>\n",
      "    </bf:contribution>\n",
      "    <bf:subject>\n",
      "      <bf:Topic rdf:about=\"http://literarybibliography.eu/subjects/00000002\">\n",
      "        <rdfs:label>Literatura</rdfs:label>\n",
      "      </bf:Topic>\n",
      "    </bf:subject>\n",
      "    <bf:title>\n",
      "      <bf:Title rdf:nodeID=\"N70ac79b5f2bd47ae8fafb0cc0aabbc06\">\n",
      "        <bf:mainTitle>Pożądanie w przekładzie</bf:mainTitle>\n",
      "      </bf:Title>\n",
      "    </bf:title>\n",
      "    <bf:summary>\n",
      "      <bf:Summary rdf:nodeID=\"Nb2a21360d8e148209de0e462b11616d3\">\n",
      "        <rdfs:label>„Postkolonialny wiersz miłosny” Natalie Diaz to pierwszy zbiór wierszy rdzennej Amerykanki w całości przełożony na polski. Przy tej okazji, zamiast szufladki na „autentyczne” wyznania rdzennych autorek, potrzebujemy pogłębionego namysłu nad związkami etniczności i eksperymentu</rdfs:label>\n",
      "      </bf:Summary>\n",
      "    </bf:summary>\n",
      "    <bf:genreForm>\n",
      "      <bf:GenreForm rdf:nodeID=\"N4f952075003c497396eb1eb665ce4fd6\">\n",
      "        <rdfs:label>recenzja</rdfs:label>\n",
      "      </bf:GenreForm>\n",
      "    </bf:genreForm>\n",
      "  </bf:Work>\n",
      "  <bf:Agent rdf:about=\"http://literarybibliography.eu/agents/00000001\">\n",
      "    <rdf:type rdf:resource=\"http://id.loc.gov/ontologies/bibframe/Person\"/>\n",
      "    <rdfs:label>Jakub Socha</rdfs:label>\n",
      "    <bf:identifiedBy>\n",
      "      <bf:Identifier rdf:nodeID=\"N61d9af29546641dcbd2429446d732193\">\n",
      "        <rdf:value>https://viaf.org/viaf/166352944/</rdf:value>\n",
      "      </bf:Identifier>\n",
      "    </bf:identifiedBy>\n",
      "  </bf:Agent>\n",
      "  <bf:Item rdf:about=\"http://literarybibliography.eu/items/00000001\">\n",
      "    <bf:itemOf rdf:resource=\"http://literarybibliography.eu/instances/00000001\"/>\n",
      "    <bf:electronicLocator rdf:resource=\"https://www.dwutygodnik.com/artykul/11242-podanie-w-przekadzie.html\"/>\n",
      "    <bf:enumerationAndChronology>\n",
      "      <bf:Enumeration rdf:nodeID=\"N482defed19ab453eaae883e8f3f7cb2b\">\n",
      "        <rdfs:label>384</rdfs:label>\n",
      "      </bf:Enumeration>\n",
      "    </bf:enumerationAndChronology>\n",
      "  </bf:Item>\n",
      "  <bf:Role rdf:about=\"http://id.loc.gov/vocabulary/relators/aut\">\n",
      "    <rdfs:label>author</rdfs:label>\n",
      "  </bf:Role>\n",
      "</rdf:RDF>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(g.serialize(format=\"pretty-xml\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WORK-C118PQ75",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

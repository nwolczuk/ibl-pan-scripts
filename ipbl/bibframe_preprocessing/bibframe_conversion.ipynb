{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "import os\n",
    "\n",
    "from rdflib import Graph, Namespace, URIRef, Literal, BNode\n",
    "from rdflib.namespace import RDF, RDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init operations\n",
    "ELB = Namespace(\"http://literarybibliography.eu/\")\n",
    "BF = Namespace(\"http://id.loc.gov/ontologies/bibframe/\")\n",
    "\n",
    "uri_base = 'http://literarybibliography.eu/'\n",
    "output_df = pd.DataFrame(columns=['subject', 'type', 'predicate', 'object'])\n",
    "\n",
    "entities_dict = {\n",
    "        'authors': {},\n",
    "        'subjects': {},\n",
    "        'genreforms': {},\n",
    "    }\n",
    "\n",
    "flow_control = {\n",
    "        'work_last_id': 0,\n",
    "        'instance_last_id': 0,\n",
    "        'item_last_id': 0,\n",
    "        'topic_last_id': 0,\n",
    "        'genreform_last_id': 0,\n",
    "        'author_last_id': 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_df(df_name):\n",
    "    df = pd.read_excel('preprocessing_input/' + df_name).fillna('')\n",
    "    df = df[df['do PBL'] == True]\n",
    "    df = df[~df['Autor'].str.contains('\\|', na=False)]\n",
    "    return df\n",
    "\n",
    "def clear_viaf_uri(url):\n",
    "    if uri := re.match(r'https://viaf\\.org/viaf/\\d+', url):\n",
    "        return uri.group(0) + '/'\n",
    "    \n",
    "def get_viaf_label(url):\n",
    "    if viaf_uri := clear_viaf_uri(url):\n",
    "        url = viaf_uri + 'viaf.json'\n",
    "        response = requests.get(url)\n",
    "        if response.ok:\n",
    "            if 'redirect' not in response.json():\n",
    "                try:\n",
    "                    label = response.json()['mainHeadings']['data'][0]['text']\n",
    "                except KeyError:\n",
    "                    label = response.json()['mainHeadings']['data']['text']\n",
    "                return label\n",
    "    \n",
    "def get_filmpolski_label(url):\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = bs(response.text, 'lxml')\n",
    "        label = soup.find('article', {'id': 'film'}).find('h1').text\n",
    "        return label\n",
    "\n",
    "def preprocess_authors(df, with_viaf=False):\n",
    "    authors_list = set(zip(df['Autor'], df['VIAF autor 1'], df['VIAF autor 2'], df['VIAF autor 3']))\n",
    "    for author_tuple in authors_list:\n",
    "        author_splitted = author_tuple[0].split('|')\n",
    "        for idx, aut in enumerate(author_splitted):\n",
    "            if idx > 2: break\n",
    "            label = aut.strip()\n",
    "            if (viaf_url := author_tuple[idx + 1]):\n",
    "                if with_viaf:\n",
    "                    viaf_label = get_viaf_label(viaf_url)\n",
    "                else: viaf_label = None\n",
    "                viaf_uri = clear_viaf_uri(viaf_url)\n",
    "            else:\n",
    "                viaf_label = None\n",
    "                viaf_uri = None   \n",
    "            if label not in entities_dict['authors']:\n",
    "                last_id = flow_control['author_last_id']\n",
    "                author_id = str(last_id + 1).zfill(8)\n",
    "                entities_dict['authors'][label] = {\n",
    "                        'author_id': author_id,\n",
    "                        'viaf_uri': viaf_uri,\n",
    "                        'viaf_label': viaf_label,\n",
    "                        'bibframe_type': 'bf:Agent',\n",
    "                    }\n",
    "                flow_control['author_last_id'] += 1\n",
    "            \n",
    "def preprocess_topics(df):\n",
    "    topics_map = {\n",
    "            'czasopismo': 'Work',\n",
    "            'film': 'MovingImage',\n",
    "            'instytucja': 'Organization',\n",
    "            'kraj': 'Place',\n",
    "            'książka': 'Work',\n",
    "            'miejscowość': 'Place',\n",
    "            'osoba': 'Person',\n",
    "            'spektakl': 'Work',\n",
    "            'wydarzenie': 'Event',\n",
    "        }\n",
    "    \n",
    "    # entities\n",
    "    df_entities = df[['byt 1', 'zewnętrzny identyfikator bytu 1', 'byt 2', 'zewnętrzny identyfikator bytu 2', 'byt 3', 'zewnętrzny identyfikator bytu 3']]\n",
    "    entities_list = list(zip(df_entities['byt 1'], df_entities['zewnętrzny identyfikator bytu 1'])) + list(zip(df_entities['byt 2'], df_entities['zewnętrzny identyfikator bytu 2'])) + list(zip(df_entities['byt 3'], df_entities['zewnętrzny identyfikator bytu 3']))\n",
    "    entities_list = [e for e in entities_list if e[0] and e[1]]\n",
    "        \n",
    "    for elem in entities_list:\n",
    "        if elem[1].startswith('https://viaf.org/'):\n",
    "            continue\n",
    "            # label = get_viaf_label(elem[1])\n",
    "            # if label:\n",
    "            #    uri = clear_viaf_uri(url)\n",
    "            #    key = uri\n",
    "            #    bibframe_type = 'bf:' + topics_map[elem[0]]\n",
    "        elif elem[1].startswith('https://filmpolski.pl/'):\n",
    "            try:\n",
    "                label = get_filmpolski_label(elem[1])\n",
    "            except: continue\n",
    "            if label:\n",
    "                uri = elem[1]\n",
    "                key = uri\n",
    "                bibframe_type = 'bf:' + topics_map[elem[0]]\n",
    "        else:\n",
    "            continue\n",
    "        if key and key not in entities_dict['subjects']:\n",
    "            last_id = flow_control['topic_last_id']\n",
    "            topic_uri = uri_base + 'subjects/subject' + str(last_id + 1).zfill(8)\n",
    "            entities_dict['subjects'][key] = {\n",
    "                    'label': label,\n",
    "                    'uri': topic_uri,\n",
    "                    'external_uri': uri,\n",
    "                    'bibframe_type': bibframe_type,\n",
    "                }\n",
    "            flow_control['topic_last_id'] += 1\n",
    "    \n",
    "    # other subjects\n",
    "    try:\n",
    "        topics = set(df['Sekcja'])\n",
    "        for topic in topics:\n",
    "            if topic not in entities_dict['subjects']:\n",
    "                last_id = flow_control['topic_last_id']\n",
    "                topic_id = str(last_id + 1).zfill(8)\n",
    "                entities_dict['subjects'][topic] = {\n",
    "                        'topic_id': topic_id,\n",
    "                        'external_uri': None,\n",
    "                        'bibframe_type': 'bf:Topic',\n",
    "                    }\n",
    "                flow_control['topic_last_id'] += 1\n",
    "    except KeyError:\n",
    "        pass\n",
    "        \n",
    "def preprocess_forms(df):\n",
    "    forms = [\n",
    "                'artykuł', \n",
    "                'esej',\n",
    "                'felieton',\n",
    "                'inne',\n",
    "                'kalendarium',\n",
    "                'kult',\n",
    "                'list',\n",
    "                'miniatura prozą',\n",
    "                'nota',\n",
    "                'opowiadanie',\n",
    "                'poemat',\n",
    "                'proza',\n",
    "                'proza poetycka',\n",
    "                'recenzja',\n",
    "                'reportaż',\n",
    "                'rozmyślanie religijne',\n",
    "                'scenariusz',\n",
    "                'słownik',\n",
    "                'sprostowanie',\n",
    "                'szkic',\n",
    "                'teksty dramatyczne',\n",
    "                'wiersz',\n",
    "                'wpis blogowy',\n",
    "                'wspomnienie',\n",
    "                'wypowiedź',\n",
    "                'wywiad',\n",
    "                'zgon',\n",
    "            ]\n",
    "    \n",
    "    for idx, form in enumerate(forms):\n",
    "        form_uri = uri_base + 'genreForms/genreform' + str(idx + 1).zfill(8)\n",
    "        entities_dict['genreforms'][form] = form_uri\n",
    "    \n",
    "def preprocess_row(idx, row):\n",
    "\n",
    "    work_id = str(flow_control.get('work_last_id') + 1).zfill(8)\n",
    "    work = ELB[f'works/{work_id}']\n",
    "    flow_control['work_last_id'] += 1\n",
    "    g.add((work, RDF.type, BF.Work))\n",
    "    \n",
    "    instance_id = str(flow_control.get('instance_last_id') + 1).zfill(8)\n",
    "    instance = ELB[f'instances/{instance_id}']\n",
    "    flow_control['instance_last_id'] += 1\n",
    "    g.add((work, BF.hasInstance, instance))\n",
    "    g.add((instance, RDF.type, BF.Instance))\n",
    "    g.add((instance, BF.instanceOf, work))\n",
    "    \n",
    "    item_id = str(flow_control.get('item_last_id') + 1).zfill(8)\n",
    "    item = ELB[f'items/{item_id}']\n",
    "    flow_control['item_last_id'] += 1\n",
    "    g.add((instance, BF.hasItem, item))\n",
    "    g.add((item, RDF.type, BF.Item))\n",
    "    g.add((item, BF.itemOf, instance))\n",
    "\n",
    "    for col, value in row.items():\n",
    "        # value = value.item()\n",
    "        value = str(value)\n",
    "        match col:\n",
    "            case 'Link':\n",
    "                g.add((item, BF.electronicLocator, URIRef(value.strip())))\n",
    "                \n",
    "            case 'Data publikacji':\n",
    "                g.add((instance, BF.originDate, Literal(value.strip())))\n",
    "                \n",
    "            case 'Autor':\n",
    "                for author in value.split('|'):\n",
    "                    author_dct = entities_dict['authors'].get(author.strip())\n",
    "                    if author_dct:\n",
    "                        author_id, viaf_uri, viaf_label = author_dct['author_id'], author_dct['viaf_uri'], author_dct['viaf_label'] # it is possible to use locals().update(author_dct)\n",
    "                        label = viaf_label if viaf_label else author\n",
    "                        \n",
    "                        # create an Agent\n",
    "                        agent = ELB[f'agents/{author_id}']\n",
    "                        g.add((agent, RDF.type, BF.Agent))\n",
    "                        g.add((agent, RDF.type, BF.Person))\n",
    "                        g.add((agent, RDFS.label, Literal(label)))\n",
    "                        if viaf_uri and (agent, BF.identifiedBy, None) not in g:\n",
    "                            identifier = BNode()\n",
    "                            g.add((identifier, RDF.type, BF.Identifier))\n",
    "                            g.add((identifier, RDF.value, Literal(viaf_uri)))\n",
    "                            g.add((agent, BF.identifiedBy, identifier))\n",
    "        \n",
    "                        # add Agent\n",
    "                        contribution = BNode()\n",
    "                        g.add((work, BF.contribution, contribution))\n",
    "                        g.add((contribution, RDF.type, BF.Contribution))\n",
    "                        g.add((contribution, RDF.type, BF.PrimaryContribution))\n",
    "                        g.add((contribution, BF.agent, agent))\n",
    "\n",
    "                        # add role\n",
    "                        author_role = URIRef('http://id.loc.gov/vocabulary/relators/aut')\n",
    "                        g.add((contribution, BF.role, author_role))\n",
    "                        g.add((author_role, RDF.type, BF.Role))\n",
    "                        g.add((author_role, RDFS.label, Literal('author')))\n",
    "                \n",
    "            case 'do PBL':\n",
    "                pass\n",
    "            \n",
    "            case 'VIAF autor 1':\n",
    "                pass\n",
    "            \n",
    "            case 'VIAF autor 2':\n",
    "                pass\n",
    "            \n",
    "            case 'VIAF autor 3':\n",
    "                pass\n",
    "            \n",
    "            case 'Sekcja':\n",
    "                topic_dct = entities_dict['subjects'].get(value.strip())\n",
    "                if topic_dct:\n",
    "                    topic_id = topic_dct['topic_id']\n",
    "                    topic = ELB[f'subjects/{topic_id}']\n",
    "                    g.add((work, BF.subject, topic))\n",
    "                    g.add((topic, RDF.type, BF.Topic))\n",
    "                    g.add((topic, RDFS.label, Literal(value.strip())))\n",
    "                \n",
    "            case 'Tytuł artykułu':                \n",
    "                title = BNode()\n",
    "                g.add((work, BF.title, title))\n",
    "                g.add((title, RDF.type, BF.Title))\n",
    "                g.add((title, BF.mainTitle, Literal(value.strip())))\n",
    "                \n",
    "            case 'Opis':\n",
    "                summary = BNode()\n",
    "                g.add((work, BF.summary, summary))\n",
    "                g.add((summary, RDF.type, BF.Summary))\n",
    "                g.add((summary, RDFS.label, Literal(value.strip())))\n",
    "                \n",
    "            case 'Numer':\n",
    "                enumeration = BNode()\n",
    "                g.add((item, BF.enumerationAndChronology, enumeration))\n",
    "                g.add((enumeration, RDF.type, BF.Enumeration))\n",
    "                if isinstance(value, float): value = int(value)\n",
    "                g.add((enumeration, RDFS.label, Literal(str(value).strip())))\n",
    "            \n",
    "            case 'Tagi':\n",
    "                for tag in value.split('|'):\n",
    "                    topic_dct = entities_dict['subjects'].get(tag.strip())\n",
    "                    if topic_dct:\n",
    "                        topic_id = topic_dct['topic_id']\n",
    "                        topic = ELB[f'subjects/{topic_id}']\n",
    "                        g.add((work, BF.subject, topic))\n",
    "                        g.add((topic, RDF.type, BF.Topic))\n",
    "                        g.add((topic, RDFS.label, Literal(value.strip())))\n",
    "\n",
    "            case 'forma/gatunek':\n",
    "                genreform = BNode()\n",
    "                g.add((work, BF.genreForm, genreform))\n",
    "                g.add((genreform, RDF.type, BF.GenreForm))\n",
    "                g.add((genreform, RDFS.label, Literal(value.strip())))\n",
    "                \n",
    "            case 'hasła przedmiotowe':\n",
    "                # matching with lcsh\n",
    "                pass\n",
    "            \n",
    "            case 'zewnętrzny identyfikator bytu 1' | 'zewnętrzny identyfikator bytu 2' | 'zewnętrzny identyfikator bytu 3':\n",
    "                topic_dct = entities_dict['subjects'].get(value.strip())\n",
    "                if topic_dct:\n",
    "                    match topic_dct['bibframe_type']:\n",
    "                        case 'bf:Work':\n",
    "                            pass\n",
    "                        case 'bf:MovingImage':\n",
    "                            uri = topic_dct['external_uri']\n",
    "                            movie_work = URIRef(uri)\n",
    "                            g.add((work, BF.subject, movie_work))\n",
    "                            g.add((movie_work, RDF.type, BF.Work))\n",
    "                            g.add((movie_work, RDF.type, BF.MovingImage))\n",
    "                            title = BNode()\n",
    "                            g.add((movie_work, BF.title, title))\n",
    "                            g.add((title, RDF.type, BF.Title))\n",
    "                            g.add((title, BF.mainTitle, Literal(topic_dct['label'])))\n",
    "                        case 'bf:Organization':\n",
    "                            pass\n",
    "                        case 'bf:Place':\n",
    "                            pass\n",
    "                        case 'bf:Person':\n",
    "                            pass\n",
    "                        case 'bf:Event':\n",
    "                            pass\n",
    "            \n",
    "            case 'byt 1':\n",
    "                pass\n",
    "\n",
    "            case 'byt 2':\n",
    "                pass\n",
    "            \n",
    "            case 'byt 3':\n",
    "                pass\n",
    "            \n",
    "            case 'adnotacje':\n",
    "                pass\n",
    "            \n",
    "            case 'Linki zewnętrzne':\n",
    "                pass\n",
    "            \n",
    "            case 'Linki do zdjęć':\n",
    "                pass\n",
    "\n",
    "            case _:\n",
    "                pass\n",
    "\n",
    "\n",
    "def preprocess_df(df):\n",
    "    preprocess_authors(df)\n",
    "    preprocess_topics(df)\n",
    "    preprocess_forms(df)\n",
    "    for index, row in df.iterrows():\n",
    "        preprocess_row(index, row)\n",
    "\n",
    "def save_graph(graph, name='output', dst='preprocessing_output/'):\n",
    "    graph.serialize(destination=f\"{dst}{name}.bibframe.xml\", format=\"pretty-xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "with os.scandir('preprocessing_input') as files:\n",
    "    for file in tqdm(files):\n",
    "        if file.is_file():\n",
    "            g = Graph()\n",
    "            g.bind(\"elb\", ELB)\n",
    "            g.bind(\"bf\", BF)\n",
    "            df = load_input_df(file.name)\n",
    "            preprocess_df(df)\n",
    "            save_graph(g, name=file.name[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to one bibframe file\n",
    "g = Graph()\n",
    "g.bind(\"elb\", ELB)\n",
    "g.bind(\"bf\", BF)\n",
    "with os.scandir('preprocessing_input') as files:\n",
    "    for file in tqdm(files):\n",
    "        if file.is_file():\n",
    "            df = load_input_df(file.name)\n",
    "            preprocess_df(df)\n",
    "save_graph(g, name='ipbl_full', dst='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
